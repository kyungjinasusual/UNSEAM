{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sherlock ë°ì´í„° ì „ì²˜ë¦¬ í™•ì¸ ë° BSDS í”¼íŒ… ì¤€ë¹„\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë‹¤ìŒì„ í™•ì¸í•©ë‹ˆë‹¤:\n",
    "1. Sherlock ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ\n",
    "2. ë°ì´í„° í˜•íƒœ ë° í’ˆì§ˆ ê²€ì¦\n",
    "3. BSDS ëª¨ë¸ì— ë§žëŠ” ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "4. Human boundaryì™€ì˜ ë¹„êµë¥¼ ìœ„í•œ ì¤€ë¹„\n",
    "\n",
    "**ì›Œí¬í”Œë¡œìš°**: ë¡œì»¬ ì½”ë“œ ìƒì„± â†’ git push â†’ ì„œë²„ì—ì„œ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# BSDS modules\n",
    "from hmm_baseline.data_loaders import (\n",
    "    load_sherlock_figshare,\n",
    "    get_sherlock_human_boundaries,\n",
    "    SHERLOCK_HUMAN_BOUNDARIES,\n",
    "    DatasetInfo\n",
    ")\n",
    "from bsds_complete.utils.data_utils import validate_input, preprocess_data, concatenate_subjects\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sherlock ë°ì´í„°ì…‹ ì •ë³´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sherlock ë°ì´í„°ì…‹ ì •ë³´\n",
    "sherlock_info = DatasetInfo.SHERLOCK\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Sherlock Dataset Information\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in sherlock_info.items():\n",
    "    print(f\"{key:25s}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Human-Annotated Boundaries\")\n",
    "print(\"=\" * 60)\n",
    "human_info = get_sherlock_human_boundaries(TR=1.5)\n",
    "print(f\"Number of boundaries: {human_info['n_boundaries']}\")\n",
    "print(f\"TR: {human_info['TR']} seconds\")\n",
    "print(f\"First 5 TRs: {human_info['tr_indices'][:5]}\")\n",
    "print(f\"First 5 timestamps (sec): {human_info['timestamps'][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ìƒíƒœ í™•ì¸\n",
    "\n",
    "### ë‹¤ìš´ë¡œë“œ ë°©ë²• (ì„œë²„ì—ì„œ ì‹¤í–‰)\n",
    "```bash\n",
    "mkdir -p ~/data/sherlock\n",
    "cd ~/data/sherlock\n",
    "\n",
    "# Figshareì—ì„œ ë‹¤ìš´ë¡œë“œ (ì•½ 500MB)\n",
    "wget -O sherlock_atlas_data.zip \"https://figshare.com/ndownloader/files/9021937\"\n",
    "unzip sherlock_atlas_data.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì • (ì„œë²„ í™˜ê²½ì— ë§žê²Œ ìˆ˜ì •)\n",
    "SHERLOCK_DATA_DIR = Path.home() / \"data\" / \"sherlock\"\n",
    "\n",
    "# ëŒ€ì²´ ê²½ë¡œë“¤ ì‹œë„\n",
    "alternative_paths = [\n",
    "    Path.home() / \"data\" / \"sherlock\",\n",
    "    Path(\"/storage/bigdata/sherlock\"),\n",
    "    Path(\"/scratch/sherlock\"),\n",
    "    project_root.parent / \"data\" / \"sherlock\",\n",
    "]\n",
    "\n",
    "data_dir = None\n",
    "for path in alternative_paths:\n",
    "    if path.exists():\n",
    "        data_dir = path\n",
    "        print(f\"âœ… Found data directory: {data_dir}\")\n",
    "        break\n",
    "\n",
    "if data_dir is None:\n",
    "    print(\"âŒ Sherlock data directory not found.\")\n",
    "    print(\"\\nPlease download data using the following commands:\")\n",
    "    print(\"\"\"    \n",
    "    mkdir -p ~/data/sherlock\n",
    "    cd ~/data/sherlock\n",
    "    wget -O sherlock_atlas_data.zip \"https://figshare.com/ndownloader/files/9021937\"\n",
    "    unzip sherlock_atlas_data.zip\n",
    "    \"\"\")\n",
    "else:\n",
    "    # íŒŒì¼ ëª©ë¡ í™•ì¸\n",
    "    npy_files = list(data_dir.glob(\"*.npy\"))\n",
    "    print(f\"\\nFound {len(npy_files)} .npy files:\")\n",
    "    for f in sorted(npy_files):\n",
    "        size_mb = f.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  - {f.name}: {size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë°ì´í„° ë¡œë“œ ë° í˜•íƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sherlock_data(data_dir: Path):\n",
    "    \"\"\"Sherlock ë°ì´í„° ê²€ì¦ í•¨ìˆ˜\"\"\"\n",
    "    if not data_dir or not data_dir.exists():\n",
    "        print(\"âŒ Data directory not available. Skipping data check.\")\n",
    "        return None\n",
    "    \n",
    "    # ROI ë³„ ë°ì´í„° ë¡œë“œ\n",
    "    roi_list = ['AG', 'PMC', 'EAC', 'PPA', 'PCC']\n",
    "    data_info = {}\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Loading Sherlock ROI Data\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for roi in roi_list:\n",
    "        roi_file = data_dir / f\"{roi}_movie_1TR.npy\"\n",
    "        if not roi_file.exists():\n",
    "            roi_file = data_dir / f\"{roi}.npy\"\n",
    "        \n",
    "        if roi_file.exists():\n",
    "            data = np.load(roi_file)\n",
    "            data_info[roi] = {\n",
    "                'file': roi_file.name,\n",
    "                'shape': data.shape,\n",
    "                'dtype': str(data.dtype),\n",
    "                'min': float(np.min(data)),\n",
    "                'max': float(np.max(data)),\n",
    "                'mean': float(np.mean(data)),\n",
    "                'std': float(np.std(data)),\n",
    "                'nan_count': int(np.sum(np.isnan(data))),\n",
    "                'inf_count': int(np.sum(np.isinf(data))),\n",
    "                'data': data\n",
    "            }\n",
    "            print(f\"\\nâœ… {roi}:\")\n",
    "            print(f\"   Shape: {data.shape}\")\n",
    "            print(f\"   Stats: min={data_info[roi]['min']:.3f}, max={data_info[roi]['max']:.3f}\")\n",
    "            print(f\"          mean={data_info[roi]['mean']:.3f}, std={data_info[roi]['std']:.3f}\")\n",
    "            print(f\"   NaN/Inf: {data_info[roi]['nan_count']}/{data_info[roi]['inf_count']}\")\n",
    "        else:\n",
    "            print(f\"âŒ {roi}: File not found\")\n",
    "    \n",
    "    return data_info\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "data_info = check_sherlock_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë°ì´í„° í˜•íƒœ ë¶„ì„ ë° BSDS í˜¸í™˜ì„± í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_for_bsds(data_info: dict):\n",
    "    \"\"\"BSDS ëª¨ë¸ì— ëŒ€í•œ ë°ì´í„° í˜¸í™˜ì„± ë¶„ì„\"\"\"\n",
    "    if data_info is None:\n",
    "        print(\"âŒ No data to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BSDS Compatibility Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # BSDS expects: List of (D x T) arrays\n",
    "    # D = number of ROIs/dimensions\n",
    "    # T = number of time points\n",
    "    \n",
    "    for roi, info in data_info.items():\n",
    "        if 'data' not in info:\n",
    "            continue\n",
    "            \n",
    "        data = info['data']\n",
    "        shape = data.shape\n",
    "        \n",
    "        print(f\"\\n{roi}:\")\n",
    "        print(f\"  Original shape: {shape}\")\n",
    "        \n",
    "        if data.ndim == 3:\n",
    "            # (n_subjects, n_timepoints, n_voxels)\n",
    "            n_subjects, n_timepoints, n_voxels = shape\n",
    "            print(f\"  Interpretation: {n_subjects} subjects Ã— {n_timepoints} TRs Ã— {n_voxels} voxels\")\n",
    "            print(f\"  âœ… Multi-subject format detected\")\n",
    "            \n",
    "            # BSDS format: List of (D x T) arrays\n",
    "            # ì—¬ê¸°ì„œ D = n_voxels, T = n_timepoints\n",
    "            print(f\"  BSDS format: List of ({n_voxels} Ã— {n_timepoints}) arrays, {n_subjects} subjects\")\n",
    "            \n",
    "        elif data.ndim == 2:\n",
    "            # Could be (n_timepoints, n_voxels) or (n_voxels, n_timepoints)\n",
    "            print(f\"  Could be: ({shape[0]} TRs Ã— {shape[1]} voxels) OR ({shape[0]} voxels Ã— {shape[1]} TRs)\")\n",
    "            \n",
    "            # Sherlock has ~1976 TRs (48 min / 1.5s)\n",
    "            if shape[0] > 1900 and shape[0] < 2000:\n",
    "                print(f\"  âš ï¸ Likely (TRs Ã— voxels) - needs transpose for BSDS\")\n",
    "            elif shape[1] > 1900 and shape[1] < 2000:\n",
    "                print(f\"  âœ… Likely (voxels Ã— TRs) - correct for BSDS\")\n",
    "        \n",
    "        # Data quality checks\n",
    "        print(f\"  Quality:\")\n",
    "        print(f\"    - NaN values: {info['nan_count']} ({'âŒ FIX REQUIRED' if info['nan_count'] > 0 else 'âœ… OK'})\")\n",
    "        print(f\"    - Inf values: {info['inf_count']} ({'âŒ FIX REQUIRED' if info['inf_count'] > 0 else 'âœ… OK'})\")\n",
    "        \n",
    "        # Check if z-scored\n",
    "        is_zscored = abs(info['mean']) < 0.1 and 0.5 < info['std'] < 2.0\n",
    "        print(f\"    - Z-scored: {'âœ… Yes (likely)' if is_zscored else 'âš ï¸ No (preprocessing needed)'}\")\n",
    "\n",
    "analyze_data_for_bsds(data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BSDSìš© ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_bsds(data_info: dict, roi: str = 'AG') -> list:\n",
    "    \"\"\"\n",
    "    BSDS ëª¨ë¸ìš© ë°ì´í„° ì¤€ë¹„\n",
    "    \n",
    "    BSDS expects: List of (D x T) arrays\n",
    "    - D = number of dimensions (ROIs/voxels)\n",
    "    - T = number of time points\n",
    "    \n",
    "    Returns:\n",
    "        List of preprocessed data arrays, one per subject\n",
    "    \"\"\"\n",
    "    if data_info is None or roi not in data_info:\n",
    "        print(f\"âŒ Data for ROI '{roi}' not available\")\n",
    "        return None\n",
    "    \n",
    "    data = data_info[roi]['data']\n",
    "    \n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Preparing {roi} data for BSDS\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Original shape: {data.shape}\")\n",
    "    \n",
    "    # Convert to list of (D x T) arrays\n",
    "    data_list = []\n",
    "    \n",
    "    if data.ndim == 3:\n",
    "        # (n_subjects, n_timepoints, n_voxels)\n",
    "        n_subjects = data.shape[0]\n",
    "        for i in range(n_subjects):\n",
    "            # Transpose to (D x T) = (n_voxels x n_timepoints)\n",
    "            subj_data = data[i, :, :].T  # (V x T)\n",
    "            data_list.append(subj_data)\n",
    "            \n",
    "    elif data.ndim == 2:\n",
    "        # Single subject or need to infer orientation\n",
    "        if data.shape[0] > 1900 and data.shape[0] < 2000:\n",
    "            # (T x D) -> transpose to (D x T)\n",
    "            data_list.append(data.T)\n",
    "        else:\n",
    "            # Already (D x T)\n",
    "            data_list.append(data)\n",
    "    \n",
    "    # Apply preprocessing to each subject\n",
    "    print(f\"\\nApplying preprocessing...\")\n",
    "    preprocessed_list = []\n",
    "    \n",
    "    for i, d in enumerate(data_list):\n",
    "        # Use BSDS preprocess function\n",
    "        d_preprocessed = preprocess_data(d, standardize=True, detrend=True)\n",
    "        preprocessed_list.append(d_preprocessed)\n",
    "        \n",
    "        print(f\"  Subject {i+1}: {d.shape} -> preprocessed\")\n",
    "        print(f\"    Mean: {np.mean(d_preprocessed):.6f}, Std: {np.std(d_preprocessed):.3f}\")\n",
    "    \n",
    "    # Validate using BSDS utility\n",
    "    print(f\"\\nValidating BSDS input format...\")\n",
    "    try:\n",
    "        n_dims, n_samples_list, n_subjects = validate_input(preprocessed_list)\n",
    "        print(f\"âœ… Valid BSDS input!\")\n",
    "        print(f\"   Dimensions (D): {n_dims}\")\n",
    "        print(f\"   Subjects: {n_subjects}\")\n",
    "        print(f\"   Samples per subject: {n_samples_list}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Validation failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return preprocessed_list\n",
    "\n",
    "# AG ROIë¡œ ì „ì²˜ë¦¬\n",
    "if data_info is not None and 'AG' in data_info:\n",
    "    bsds_data = prepare_for_bsds(data_info, roi='AG')\n",
    "else:\n",
    "    print(\"âš ï¸ Skipping preprocessing - data not loaded\")\n",
    "    bsds_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë°ì´í„° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sherlock_data(data_list: list, human_boundaries: np.ndarray, TR: float = 1.5):\n",
    "    \"\"\"Sherlock ë°ì´í„° ë° human boundary ì‹œê°í™”\"\"\"\n",
    "    if data_list is None:\n",
    "        print(\"âŒ No data to visualize\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Use first subject\n",
    "    data = data_list[0]\n",
    "    D, T = data.shape\n",
    "    time_min = np.arange(T) * TR / 60  # Convert to minutes\n",
    "    \n",
    "    # 1. Time series heatmap\n",
    "    ax = axes[0]\n",
    "    im = ax.imshow(data, aspect='auto', cmap='RdBu_r', \n",
    "                   extent=[0, time_min[-1], D, 0],\n",
    "                   vmin=-3, vmax=3)\n",
    "    ax.set_xlabel('Time (minutes)')\n",
    "    ax.set_ylabel('Voxel')\n",
    "    ax.set_title(f'Sherlock fMRI Data - Subject 1 (D={D}, T={T})')\n",
    "    plt.colorbar(im, ax=ax, label='Z-scored BOLD')\n",
    "    \n",
    "    # Add human boundaries\n",
    "    for hb in human_boundaries:\n",
    "        ax.axvline(hb * TR / 60, color='lime', linewidth=1, alpha=0.7)\n",
    "    \n",
    "    # 2. Mean time series with boundaries\n",
    "    ax = axes[1]\n",
    "    mean_ts = np.mean(data, axis=0)\n",
    "    ax.plot(time_min, mean_ts, 'b-', linewidth=0.5, alpha=0.7)\n",
    "    ax.fill_between(time_min, mean_ts - np.std(data, axis=0), \n",
    "                    mean_ts + np.std(data, axis=0), alpha=0.3)\n",
    "    \n",
    "    # Add boundaries\n",
    "    for hb in human_boundaries:\n",
    "        ax.axvline(hb * TR / 60, color='green', linewidth=1, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Time (minutes)')\n",
    "    ax.set_ylabel('Mean BOLD (z-score)')\n",
    "    ax.set_title('Mean Time Series with Human-Annotated Event Boundaries (green)')\n",
    "    ax.legend(['Mean Â± Std', 'Human Boundaries'], loc='upper right')\n",
    "    \n",
    "    # 3. Event duration histogram\n",
    "    ax = axes[2]\n",
    "    event_starts = np.concatenate([[0], human_boundaries])\n",
    "    event_durations = np.diff(np.concatenate([event_starts, [T]])) * TR\n",
    "    \n",
    "    ax.hist(event_durations, bins=15, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(np.mean(event_durations), color='red', linestyle='--', \n",
    "               label=f'Mean: {np.mean(event_durations):.1f}s')\n",
    "    ax.axvline(np.median(event_durations), color='orange', linestyle='--',\n",
    "               label=f'Median: {np.median(event_durations):.1f}s')\n",
    "    ax.set_xlabel('Event Duration (seconds)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Distribution of Human-Annotated Event Durations')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sherlock_data_overview.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"Event Duration Statistics\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Number of events: {len(event_durations)}\")\n",
    "    print(f\"Mean duration: {np.mean(event_durations):.1f}s ({np.mean(event_durations)/TR:.1f} TRs)\")\n",
    "    print(f\"Median duration: {np.median(event_durations):.1f}s\")\n",
    "    print(f\"Std duration: {np.std(event_durations):.1f}s\")\n",
    "    print(f\"Min/Max: {np.min(event_durations):.1f}s / {np.max(event_durations):.1f}s\")\n",
    "\n",
    "if bsds_data is not None:\n",
    "    visualize_sherlock_data(bsds_data, SHERLOCK_HUMAN_BOUNDARIES, TR=1.5)\n",
    "else:\n",
    "    print(\"âš ï¸ Skipping visualization - data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. BSDS í”¼íŒ… ì¤€ë¹„ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsds_readiness_check(data_list: list):\n",
    "    \"\"\"BSDS í”¼íŒ…ì„ ìœ„í•œ ìµœì¢… ì¤€ë¹„ ìƒíƒœ í™•ì¸\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BSDS Fitting Readiness Check\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    checks = {\n",
    "        'data_loaded': data_list is not None,\n",
    "        'is_list': isinstance(data_list, list) if data_list else False,\n",
    "        'correct_dims': False,\n",
    "        'no_nan': False,\n",
    "        'no_inf': False,\n",
    "        'standardized': False,\n",
    "    }\n",
    "    \n",
    "    if data_list is not None and len(data_list) > 0:\n",
    "        # Check dimensions\n",
    "        all_2d = all(d.ndim == 2 for d in data_list)\n",
    "        all_same_d = len(set(d.shape[0] for d in data_list)) == 1\n",
    "        checks['correct_dims'] = all_2d and all_same_d\n",
    "        \n",
    "        # Check NaN/Inf\n",
    "        checks['no_nan'] = not any(np.any(np.isnan(d)) for d in data_list)\n",
    "        checks['no_inf'] = not any(np.any(np.isinf(d)) for d in data_list)\n",
    "        \n",
    "        # Check standardization\n",
    "        concat = np.hstack(data_list)\n",
    "        checks['standardized'] = abs(np.mean(concat)) < 0.1 and 0.5 < np.std(concat) < 2.0\n",
    "    \n",
    "    # Print results\n",
    "    all_passed = True\n",
    "    for check, passed in checks.items():\n",
    "        status = 'âœ…' if passed else 'âŒ'\n",
    "        print(f\"  {status} {check.replace('_', ' ').title()}: {passed}\")\n",
    "        if not passed:\n",
    "            all_passed = False\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    if all_passed:\n",
    "        print(\"ðŸŽ‰ All checks passed! Data is ready for BSDS fitting.\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"  1. Push code to git: git add . && git commit -m 'add sherlock preprocessing' && git push\")\n",
    "        print(\"  2. On server: git pull && python run_sherlock_bsds.py\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Some checks failed. Please fix issues before fitting.\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "bsds_readiness_check(bsds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. BSDS í”¼íŒ… í…ŒìŠ¤íŠ¸ (ì†Œê·œëª¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bsds_fitting(data_list: list, max_subjects: int = 2, n_iter: int = 10):\n",
    "    \"\"\"BSDS ëª¨ë¸ í”¼íŒ… í…ŒìŠ¤íŠ¸ (ì†Œê·œëª¨)\"\"\"\n",
    "    if data_list is None:\n",
    "        print(\"âŒ No data for testing\")\n",
    "        return None\n",
    "    \n",
    "    from bsds_complete.core.model import BSDSModel\n",
    "    from bsds_complete.core.config import BSDSConfig\n",
    "    \n",
    "    # Use subset of subjects for quick test\n",
    "    test_data = data_list[:max_subjects]\n",
    "    \n",
    "    # Subsample time points for faster testing\n",
    "    test_data_small = [d[:, ::4] for d in test_data]  # Every 4th time point\n",
    "    \n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"BSDS Fitting Test\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Subjects: {len(test_data_small)}\")\n",
    "    print(f\"Dimensions: {test_data_small[0].shape[0]}\")\n",
    "    print(f\"Time points: {[d.shape[1] for d in test_data_small]}\")\n",
    "    \n",
    "    # Configure model\n",
    "    config = BSDSConfig(\n",
    "        n_states=5,\n",
    "        max_ldim=3,\n",
    "        n_iter=n_iter,\n",
    "        n_init_learning=1,\n",
    "        n_init_iter=5,\n",
    "        TR=1.5,\n",
    "        verbose=True,\n",
    "        random_seed=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel config:\")\n",
    "    print(f\"  n_states: {config.n_states}\")\n",
    "    print(f\"  max_ldim: {config.max_ldim}\")\n",
    "    print(f\"  n_iter: {config.n_iter}\")\n",
    "    \n",
    "    # Fit model\n",
    "    print(f\"\\nFitting model...\")\n",
    "    try:\n",
    "        model = BSDSModel(config)\n",
    "        model.fit(test_data_small)\n",
    "        \n",
    "        print(f\"\\nâœ… Model fitted successfully!\")\n",
    "        \n",
    "        # Get results\n",
    "        states = model.get_states()\n",
    "        stats = model.get_summary_statistics()\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Effective states: {stats.get('effective_n_states', 'N/A')}\")\n",
    "        print(f\"  State occupancy: {stats.get('occupancy', 'N/A')}\")\n",
    "        print(f\"  Final log-likelihood: {model.log_lik_history[-1]:.2f}\")\n",
    "        \n",
    "        return model, states, stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fitting failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë°ì´í„°ê°€ ìžˆëŠ” ê²½ìš°ì—ë§Œ)\n",
    "if bsds_data is not None:\n",
    "    test_result = test_bsds_fitting(bsds_data, max_subjects=2, n_iter=10)\n",
    "else:\n",
    "    print(\"âš ï¸ Skipping BSDS test - data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì €ìž¥ ë° ë‹¤ìŒ ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessed_data(data_list: list, output_dir: Path, roi: str = 'AG'):\n",
    "    \"\"\"ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ìž¥\"\"\"\n",
    "    if data_list is None:\n",
    "        print(\"âŒ No data to save\")\n",
    "        return\n",
    "    \n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    output_file = output_dir / f\"sherlock_{roi}_preprocessed.npy\"\n",
    "    \n",
    "    # Save as object array to preserve list structure\n",
    "    np.save(output_file, np.array(data_list, dtype=object), allow_pickle=True)\n",
    "    \n",
    "    print(f\"âœ… Saved preprocessed data to: {output_file}\")\n",
    "    print(f\"   Load with: data = list(np.load('{output_file}', allow_pickle=True))\")\n",
    "\n",
    "# ì €ìž¥ (ë°ì´í„°ê°€ ìžˆëŠ” ê²½ìš°)\n",
    "if bsds_data is not None:\n",
    "    save_preprocessed_data(bsds_data, project_root / 'data' / 'sherlock_preprocessed', roi='AG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ìš”ì•½\n",
    "\n",
    "### ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "| Item | Status | Notes |\n",
    "|------|--------|-------|\n",
    "| Sherlock ë°ì´í„° ë‹¤ìš´ë¡œë“œ | â¬œ | Figshareì—ì„œ ë‹¤ìš´ë¡œë“œ í•„ìš” |\n",
    "| ë°ì´í„° í˜•íƒœ í™•ì¸ | â¬œ | (n_subjects, n_TRs, n_voxels) ì˜ˆìƒ |\n",
    "| NaN/Inf ê²€ì‚¬ | â¬œ | ì—†ì–´ì•¼ í•¨ |\n",
    "| Z-score ì „ì²˜ë¦¬ | â¬œ | BSDS ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‚¬ìš© |\n",
    "| BSDS í˜•ì‹ ë³€í™˜ | â¬œ | List of (D x T) arrays |\n",
    "| í”¼íŒ… í…ŒìŠ¤íŠ¸ | â¬œ | ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ í›„ ì „ì²´ ì‹¤í–‰ |\n",
    "\n",
    "### ì„œë²„ ì‹¤í–‰ ëª…ë ¹\n",
    "\n",
    "```bash\n",
    "# 1. ì½”ë“œ ì—…ë°ì´íŠ¸\n",
    "cd /path/to/UNSEAM\n",
    "git pull\n",
    "\n",
    "# 2. BSDS í”¼íŒ… ì‹¤í–‰\n",
    "python BSDS_Project/run_sherlock_bsds.py \\\n",
    "    --data-dir ~/data/sherlock \\\n",
    "    --roi AG \\\n",
    "    --n-states 10 \\\n",
    "    --preset balanced\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
